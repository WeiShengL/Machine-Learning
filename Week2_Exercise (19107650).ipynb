{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Machine Learning for Physicists\n",
    "## Week 2 Exercise -- Deadline Monday 26th October at 12pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week's exercise is to train some neural networks to mimic functions. The functions that you need to mimic are:\n",
    "1. A circle  [40 points]\n",
    "2. A circle with a hole [40 points]\n",
    "3. A circle with three holes [20 points]\n",
    "\n",
    "The code below is just a copy and paste of the code from the Week2_NetworkVisualisation notebook. At the bottom of the notebook the three target functions are defined.\n",
    "\n",
    "For all three exercises marks will be given for the following (equally weighted assuming the network 'succeeeds' in mimic the shape):\n",
    "- The final cost function (e.g. how well does your network match the target)\n",
    "- The network simplicity (e.g. matching the target as well with a simpler network is better)\n",
    "- The network training efficiency (e.g. getting your network trained using as little computing power as possible)\n",
    "- Notebook readability and code clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports: only numpy and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpy import array, zeros, exp, random, dot, shape, reshape, meshgrid, linspace\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi']=300 # highres display\n",
    "\n",
    "# for subplots within subplots:\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# for nice inset colorbars: (approach changed from lecture 1 'Visualization' notebook)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition\n",
    "\n",
    "# for updating display \n",
    "# (very simple animation)\n",
    "from IPython.display import clear_output\n",
    "from time import process_time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backpropagation and training routines\n",
    "\n",
    "# this is basically a merger of the backpropagation\n",
    "# code shown in lecture 2 and some of the \n",
    "# visualization code used in the lecture 1 tutorials!\n",
    "\n",
    "def net_f_df(z,activation):\n",
    "    # return both value f(z) and derivative f'(z)\n",
    "    if activation=='sigmoid':\n",
    "        return([1/(1+np.exp(-z)), \n",
    "                1/((1+np.exp(-z))*(1+np.exp(z))) ])\n",
    "    elif activation=='jump': # cheating a bit here: replacing f'(z)=delta(z) by something smooth\n",
    "        return([np.array(z>0,dtype='float'), \n",
    "                10.0/((1+np.exp(-10*z))*(1+np.exp(10*z))) ] )\n",
    "    elif activation=='linear':\n",
    "        return([z,\n",
    "                1.0])\n",
    "    elif activation=='reLU':\n",
    "        return([(z>0)*z,\n",
    "                (z>0)*1.0\n",
    "               ])\n",
    "\n",
    "def forward_step(y,w,b,activation):\n",
    "    \"\"\"\n",
    "    Go from one layer to the next, given a \n",
    "    weight matrix w (shape [n_neurons_in,n_neurons_out])\n",
    "    a bias vector b (length n_neurons_out)\n",
    "    and the values of input neurons y_in \n",
    "    (shape [batchsize,n_neurons_in])\n",
    "    \n",
    "    returns the values of the output neurons in the next layer \n",
    "    (shape [batchsize, n_neurons_out])\n",
    "    \"\"\"    \n",
    "    # calculate values in next layer, from input y\n",
    "    z=np.dot(y,w)+b # w=weights, b=bias vector for next layer\n",
    "    return(net_f_df(z,activation)) # apply nonlinearity and return result\n",
    "\n",
    "def apply_net(x_in): # one forward pass through the network\n",
    "    global Weights, Biases, NumLayers, Activations\n",
    "    global y_layer, df_layer # for storing y-values and df/dz values\n",
    "    \n",
    "    y=np.copy(x_in) # start with input values\n",
    "    y_layer[0]=np.copy(y)\n",
    "    for j in range(NumLayers): # loop through all layers\n",
    "        # j=0 corresponds to the first layer above the input\n",
    "        y,df=forward_step(y,Weights[j],Biases[j],Activations[j]) # one step\n",
    "        df_layer[j]=np.copy(df) # store f'(z) [needed later in backprop]\n",
    "        y_layer[j+1]=np.copy(y) # store f(z) [also needed in backprop]        \n",
    "    return(y)\n",
    "\n",
    "def apply_net_simple(x_in): # one forward pass through the network\n",
    "    # no storage for backprop (this is used for simple tests)\n",
    "    global Weights, Biases, NumLayers, Activations\n",
    "    \n",
    "    y=x_in # start with input values\n",
    "    for j in range(NumLayers): # loop through all layers\n",
    "        # j=0 corresponds to the first layer above the input\n",
    "        y,df=forward_step(y,Weights[j],Biases[j],Activations[j]) # one step\n",
    "    return(y)\n",
    "\n",
    "def backward_step(delta,w,df): \n",
    "    # delta at layer N, of batchsize x layersize(N))\n",
    "    # w between N-1 and N [layersize(N-1) x layersize(N) matrix]\n",
    "    # df = df/dz at layer N-1, of batchsize x layersize(N-1)\n",
    "    return( np.dot(delta,np.transpose(w))*df )\n",
    "\n",
    "def backprop(y_target): # one backward pass through the network\n",
    "    # the result will be the 'dw_layer' matrices that contain\n",
    "    # the derivatives of the cost function with respect to\n",
    "    # the corresponding weight\n",
    "    global y_layer, df_layer, Weights, Biases, NumLayers\n",
    "    global dw_layer, db_layer # dCost/dw and dCost/db (w,b=weights,biases)\n",
    "\n",
    "    batchsize=np.shape(y_target)[0]\n",
    "    delta=(y_layer[-1]-y_target)*df_layer[-1]\n",
    "    dw_layer[-1]=np.dot(np.transpose(y_layer[-2]),delta)/batchsize\n",
    "    db_layer[-1]=delta.sum(0)/batchsize\n",
    "    for j in range(NumLayers-1):\n",
    "        delta=backward_step(delta,Weights[-1-j],df_layer[-2-j])\n",
    "        dw_layer[-2-j]=np.dot(np.transpose(y_layer[-3-j]),delta)/batchsize # batchsize was missing in old code?\n",
    "        db_layer[-2-j]=delta.sum(0)/batchsize\n",
    "        \n",
    "def gradient_step(eta): # update weights & biases (after backprop!)\n",
    "    global dw_layer, db_layer, Weights, Biases\n",
    "    \n",
    "    for j in range(NumLayers):\n",
    "        Weights[j]-=eta*dw_layer[j]\n",
    "        Biases[j]-=eta*db_layer[j]\n",
    "        \n",
    "def train_net(x_in,y_target,eta): # one full training batch\n",
    "    # x_in is an array of size batchsize x (input-layer-size)\n",
    "    # y_target is an array of size batchsize x (output-layer-size)\n",
    "    # eta is the stepsize for the gradient descent\n",
    "    global y_out_result\n",
    "    \n",
    "    y_out_result=apply_net(x_in)\n",
    "    backprop(y_target)\n",
    "    gradient_step(eta)\n",
    "    cost=0.5*((y_target-y_out_result)**2).sum()/np.shape(x_in)[0]\n",
    "    return(cost)\n",
    "\n",
    "def init_layer_variables(weights,biases,activations):\n",
    "    global Weights, Biases, NumLayers, Activations\n",
    "    global LayerSizes, y_layer, df_layer, dw_layer, db_layer\n",
    "\n",
    "    Weights=weights\n",
    "    Biases=biases\n",
    "    Activations=activations\n",
    "    NumLayers=len(Weights)\n",
    "\n",
    "    LayerSizes=[2]\n",
    "    for j in range(NumLayers):\n",
    "        LayerSizes.append(len(Biases[j]))\n",
    "\n",
    "    y_layer=[[] for j in range(NumLayers+1)]\n",
    "    df_layer=[[] for j in range(NumLayers)]\n",
    "    dw_layer=[np.zeros([LayerSizes[j],LayerSizes[j+1]]) for j in range(NumLayers)]\n",
    "    db_layer=[np.zeros(LayerSizes[j+1]) for j in range(NumLayers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization routines:\n",
    "\n",
    "# some internal routines for plotting the network:\n",
    "def plot_connection_line(ax,X,Y,W,vmax=1.0,linewidth=3):\n",
    "    t=np.linspace(0,1,20)\n",
    "    if W>0:   #Pick colour of line based on if weight is positive or negative\n",
    "        col=[0,0.4,0.8]  \n",
    "    else:\n",
    "        col=[1,0.3,0]\n",
    "    ax.plot(X[0]+(3*t**2-2*t**3)*(X[1]-X[0]),Y[0]+t*(Y[1]-Y[0]),\n",
    "           alpha=abs(W)/vmax,color=col,\n",
    "           linewidth=linewidth)\n",
    "    \n",
    "def plot_neuron_alpha(ax,X,Y,B,size=100.0,vmax=1.0):\n",
    "    if B>0: #Pick colour of neuron dot based on if bias is positive or negative\n",
    "        col=[0,0.4,0.8]\n",
    "    else:\n",
    "        col=[1,0.3,0]\n",
    "    ax.scatter([X],[Y],marker='o',c=np.atleast_2d([col]),alpha=abs(B)/vmax,s=size,zorder=10)\n",
    "\n",
    "def plot_neuron(ax,X,Y,B,size=100.0,vmax=1.0):\n",
    "    if B>0:\n",
    "        col=[0,0.4,0.8]\n",
    "    else:\n",
    "        col=[1,0.3,0]\n",
    "    ax.scatter([X],[Y],marker='o',c=np.atleast_2d([col]),s=size,zorder=10)\n",
    "    \n",
    "def visualize_network(weights,biases,activations,\n",
    "                      M=100,x0range=[-1,1],x1range=[-1,1],\n",
    "                     size=400.0, linewidth=5.0,\n",
    "                     weights_are_swapped=False,\n",
    "                    layers_already_initialized=False,\n",
    "                      plot_cost_function=None,\n",
    "                      current_cost=None, cost_max=None, plot_target=None\n",
    "                     ):\n",
    "    \"\"\"\n",
    "    Visualize a neural network with 2 input \n",
    "    neurons and 1 output neuron (plot output vs input in a 2D plot)\n",
    "    \n",
    "    weights is a list of the weight matrices for the\n",
    "    layers, where weights[j] is the matrix for the connections\n",
    "    from layer j to layer j+1 (where j==0 is the input)\n",
    "    \n",
    "    weights[j][m,k] is the weight for input neuron k going to output neuron m\n",
    "    (note: internally, m and k are swapped, see the explanation of\n",
    "    batch processing in lecture 2)\n",
    "    \n",
    "    biases[j] is the vector of bias values for obtaining the neurons in layer j+1\n",
    "    biases[j][k] is the bias for neuron k in layer j+1\n",
    "    \n",
    "    activations is a list of the activation functions for\n",
    "    the different layers: choose 'linear','sigmoid',\n",
    "    'jump' (i.e. step-function), and 'reLU'\n",
    "    \n",
    "    M is the resolution (MxM grid)\n",
    "    \n",
    "    x0range is the range of x0 neuron values (horizontal axis)\n",
    "    x1range is the range of x1 neuron values (vertical axis)\n",
    "    \"\"\"\n",
    "    if not weights_are_swapped:\n",
    "        swapped_weights=[]\n",
    "        for j in range(len(weights)):\n",
    "            swapped_weights.append(np.transpose(weights[j]))\n",
    "    else:\n",
    "        swapped_weights=weights\n",
    "\n",
    "    x0,x1=np.meshgrid(np.linspace(x0range[0],x0range[1],M),np.linspace(x1range[0],x1range[1],M))\n",
    "    x_in=np.zeros([M*M,2])\n",
    "    x_in[:,0]=x0.flatten()\n",
    "    x_in[:,1]=x1.flatten()\n",
    "    \n",
    "    # if we call visualization directly, we still\n",
    "    # need to initialize the 'Weights' and other\n",
    "    # global variables; otherwise (during training)\n",
    "    # all of this has already been taken care of:\n",
    "    if not layers_already_initialized:\n",
    "        init_layer_variables(swapped_weights,biases,activations)\n",
    "    y_out=apply_net_simple(x_in)\n",
    "\n",
    "    if plot_cost_function is None:\n",
    "        fig,ax=plt.subplots(ncols=2,nrows=1,figsize=(8,4))\n",
    "    else:\n",
    "        fig=plt.figure(figsize=(8,4))\n",
    "        gs_top = gridspec.GridSpec(nrows=1, ncols=2)\n",
    "        gs_left = gridspec.GridSpecFromSubplotSpec(nrows=2, ncols=1, subplot_spec=gs_top[0], height_ratios=[1.0,0.3])\n",
    "        ax=[ fig.add_subplot(gs_left[0]),\n",
    "            fig.add_subplot(gs_top[1]),\n",
    "           fig.add_subplot(gs_left[1]) ]\n",
    "        # ax[0] is network\n",
    "        # ax[1] is image produced by network\n",
    "        # ax[2] is cost function subplot\n",
    "        \n",
    "    # plot the network itself:\n",
    "    \n",
    "    # positions of neurons on plot:\n",
    "    posX=[[-0.5,+0.5]]; posY=[[0,0]]\n",
    "    vmax=0.0 # for finding the maximum weight\n",
    "    vmaxB=0.0 # for maximum bias\n",
    "    for j in range(len(biases)):\n",
    "        n_neurons=len(biases[j])\n",
    "        posX.append(np.array(range(n_neurons))-0.5*(n_neurons-1))\n",
    "        posY.append(np.full(n_neurons,j+1))\n",
    "        vmax=np.maximum(vmax,np.max(np.abs(weights[j])))\n",
    "        vmaxB=np.maximum(vmaxB,np.max(np.abs(biases[j])))\n",
    "\n",
    "    # plot connections\n",
    "    for j in range(len(biases)):\n",
    "        for k in range(len(posX[j])):\n",
    "            for m in range(len(posX[j+1])):\n",
    "                plot_connection_line(ax[0],[posX[j][k],posX[j+1][m]],\n",
    "                                     [posY[j][k],posY[j+1][m]],\n",
    "                                     swapped_weights[j][k,m],vmax=vmax,\n",
    "                                    linewidth=linewidth)\n",
    "    \n",
    "    # plot neurons\n",
    "    for k in range(len(posX[0])): # input neurons (have no bias!)\n",
    "        plot_neuron(ax[0],posX[0][k],posY[0][k],\n",
    "                   vmaxB,vmax=vmaxB,size=size)\n",
    "    for j in range(len(biases)): # all other neurons\n",
    "        for k in range(len(posX[j+1])):\n",
    "            plot_neuron(ax[0],posX[j+1][k],posY[j+1][k],\n",
    "                       biases[j][k],vmax=vmaxB,size=size)\n",
    "    \n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    # now: the output of the network\n",
    "    img=ax[1].imshow(np.reshape(y_out,[M,M]),origin='lower',\n",
    "                    extent=[x0range[0],x0range[1],x1range[0],x1range[1]])\n",
    "    ax[1].set_xlabel(r'$x_0$')\n",
    "    ax[1].set_ylabel(r'$x_1$')\n",
    "    \n",
    "#     axins1 = inset_axes(ax[1],\n",
    "#                     width=\"40%\",  # width = 50% of parent_bbox width\n",
    "#                     height=\"5%\",  # height : 5%\n",
    "#                     loc='upper right',\n",
    "#                        bbox_to_anchor=[0.3,0.4])\n",
    "\n",
    "#    axins1 = ax[1].inset_axes([0.5,0.8,0.45,0.1])\n",
    "    axins1 = plt.axes([0, 0, 1, 1])\n",
    "    ip = InsetPosition(ax[1], [0.25, 0.1, 0.5, 0.05])\n",
    "    axins1.set_axes_locator(ip)\n",
    "\n",
    "    imgmin=np.min(y_out)\n",
    "    imgmax=np.max(y_out)\n",
    "    color_bar=fig.colorbar(img, cax=axins1, orientation=\"horizontal\",ticks=np.linspace(imgmin,imgmax,3))\n",
    "    cbxtick_obj = plt.getp(color_bar.ax.axes, 'xticklabels')\n",
    "    plt.setp(cbxtick_obj, color=\"white\")\n",
    "    axins1.xaxis.set_ticks_position(\"bottom\")\n",
    "\n",
    "    if plot_target is not None:\n",
    "        axins2 = plt.axes([0.01, 0.01, 0.99, 0.99])\n",
    "        ip = InsetPosition(ax[1], [0.75, 0.75, 0.2, 0.2])\n",
    "        axins2.set_axes_locator(ip)\n",
    "        axins2.imshow(plot_target,origin='lower')\n",
    "        axins2.get_xaxis().set_ticks([])\n",
    "        axins2.get_yaxis().set_ticks([])\n",
    "        \n",
    "    if plot_cost_function is not None:\n",
    "        ax[2].plot(plot_cost_function)\n",
    "        ax[2].set_ylim([0.0,cost_max])\n",
    "        ax[2].set_yticks([0.0,cost_max])\n",
    "        ax[2].set_yticklabels([\"0\",'{:1.2e}'.format(cost_max)])\n",
    "        if current_cost is not None:\n",
    "            ax[2].text(0.9, 0.9, 'cost={:1.2e}'.format(current_cost), horizontalalignment='right',\n",
    "                       verticalalignment='top', transform=ax[2].transAxes)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def visualize_network_training(weights,biases,activations,\n",
    "                               target_function,\n",
    "                               num_neurons=None,\n",
    "                               weight_scale=1.0,\n",
    "                               bias_scale=1.0,\n",
    "                               xspread=1.0,\n",
    "                      M=100,x0range=[-1,1],x1range=[-1,1],\n",
    "                     size=400.0, linewidth=5.0,\n",
    "                    steps=100, batchsize=10, eta=0.1,\n",
    "                              random_init=False,\n",
    "                              visualize_nsteps=1,\n",
    "                              plot_target=True):\n",
    "    \"\"\"\n",
    "    Visualize the training of a neural network.\n",
    "    \n",
    "    weights, biases, and activations define the neural network \n",
    "    (the starting point of the optimization; for the detailed description,\n",
    "    see the help for visualize_network)\n",
    "    \n",
    "    If you want to have layers randomly initialized, just provide\n",
    "    the number of neurons for each layer as 'num_neurons'. This should include\n",
    "    all layers, including input (2 neurons) and output (1), so num_neurons=[2,3,5,4,1] is\n",
    "    a valid example. In this case, weight_scale and bias_scale define the\n",
    "    spread of the random Gaussian variables used to initialize all weights and biases.\n",
    "    \n",
    "    target_function is the name of the function that we\n",
    "    want to approximate; it must be possible to \n",
    "    evaluate this function on a batch of samples, by\n",
    "    calling target_function(y) on an array y of \n",
    "    shape [batchsize,2], where\n",
    "    the second index refers to the two coordinates\n",
    "    (input neuron values) x0 and x1. The return\n",
    "    value must be an array with one index, corresponding\n",
    "    to the batchsize. A valid example is:\n",
    "    \n",
    "    def my_target(y):\n",
    "        return( np.sin(y[:,0]) + np.cos(y[:,1]) )\n",
    "    \n",
    "    steps is the number of training steps\n",
    "    \n",
    "    batchsize is the number of samples per training step\n",
    "    \n",
    "    eta is the learning rate (stepsize in the gradient descent)\n",
    "    \n",
    "    xspread denotes the spread of the Gaussian\n",
    "    used to sample points in (x0,x1)-space\n",
    "    \n",
    "    visualize_n_steps>1 means skip some steps before\n",
    "    visualizing again (can speed up things)\n",
    "    \n",
    "    plot_target=True means do plot the target function in a corner\n",
    "    \n",
    "    For all the other parameters, see the help for\n",
    "        visualize_network\n",
    "    \n",
    "    weights and biases as given here will be used\n",
    "    as starting points, unless you specify\n",
    "    random_init=True, in which case they will be\n",
    "    used to determine the spread of Gaussian random\n",
    "    variables used for initialization!\n",
    "    \"\"\"\n",
    "    \n",
    "    if num_neurons is not None: # build weight matrices as randomly initialized\n",
    "        weights=[weight_scale*np.random.randn(num_neurons[j+1],num_neurons[j]) for j in range(len(num_neurons)-1)]\n",
    "        biases=[bias_scale*np.random.randn(num_neurons[j+1]) for j in range(len(num_neurons)-1)]\n",
    "    \n",
    "    swapped_weights=[]\n",
    "    for j in range(len(weights)):\n",
    "        swapped_weights.append(np.transpose(weights[j]))\n",
    "    init_layer_variables(swapped_weights,biases,activations)\n",
    "    \n",
    "    if plot_target:\n",
    "        x0,x1=np.meshgrid(np.linspace(x0range[0],x0range[1],M),np.linspace(x1range[0],x1range[1],M))\n",
    "        y=np.zeros([M*M,2])\n",
    "        y[:,0]=x0.flatten()\n",
    "        y[:,1]=x1.flatten()\n",
    "        plot_target_values=np.reshape(target_function(y),[M,M])\n",
    "    else:\n",
    "        plot_target_values=None\n",
    "    \n",
    "    y_target=np.zeros([batchsize,1])\n",
    "    costs=np.zeros(steps)\n",
    "    \n",
    "    for j in range(steps):\n",
    "        # produce samples (random points in x0,x1-space):\n",
    "        x_in=xspread*np.random.randn(batchsize,2)\n",
    "        # apply target function to those points:\n",
    "        y_target[:,0]=target_function(x_in)\n",
    "        # do one training step on this batch of samples:\n",
    "        costs[j]=train_net(x_in,y_target,eta)\n",
    "        \n",
    "        # now visualize the updated network:\n",
    "        if j%visualize_nsteps==0:\n",
    "            clear_output(wait=True) # for animation\n",
    "            if j>10:\n",
    "                cost_max=np.average(costs[0:j])*1.5\n",
    "            else:\n",
    "                cost_max=costs[0]\n",
    "            visualize_network(Weights,Biases,activations,\n",
    "                          M,x0range=x0range,x1range=x1range,\n",
    "                         size=size, linewidth=linewidth,\n",
    "                             weights_are_swapped=True,\n",
    "                             layers_already_initialized=True,\n",
    "                             plot_cost_function=costs,\n",
    "                             current_cost=costs[j],\n",
    "                             cost_max=cost_max,\n",
    "                             plot_target=plot_target_values)\n",
    "            sleep(0.1) # wait a bit before next step (probably not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle target  [40 points]\n",
    "Train a network to mimic the following target (e.g. using the visualize_network_training function above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_target(x):  #A circle of radius 2 around the origin\n",
    "    R=2.0\n",
    "    return( 1.0*( x[:,0]**2+x[:,1]**2<R**2 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using any activation function except for \"jump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = process_time()\n",
    "\n",
    "visualize_network_training(weights=[],biases=[],\n",
    "    num_neurons=[2,16,1], # this generates randomly initialized layers of the given neuron numbers!\n",
    "    bias_scale=0.0, weight_scale=0.1, # the scale of the random numbers\n",
    "    target_function=circle_target, # the target function to approximate\n",
    "    activations=[ \n",
    "                'sigmoid',\n",
    "                 'reLU'\n",
    "                ],\n",
    "    x0range=[-3,3],x1range=[-3,3],\n",
    "    xspread=3,\n",
    "    steps=10000, eta=.1, batchsize=200,\n",
    "                          visualize_nsteps=2000)\n",
    "\n",
    "end = process_time()\n",
    "timetaken = end-start\n",
    "print(\"Time taken for output:\", timetaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Without `jump` function the diagram is not well trained\n",
    "<br>\n",
    "A `jump` function at the final connection is recommended for a well defined circle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only using 8 neurons with a single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = process_time()\n",
    "\n",
    "visualize_network_training(weights=[],biases=[],\n",
    "    num_neurons=[2,8,1], # this generates randomly initialized layers of the given neuron numbers!\n",
    "    bias_scale=0.0, weight_scale=0.1, # the scale of the random numbers\n",
    "    target_function=circle_target, # the target function to approximate\n",
    "    activations=[ \n",
    "                'reLU',\n",
    "                 'jump'\n",
    "                ],\n",
    "    x0range=[-3,3],x1range=[-3,3],\n",
    "    xspread=3,\n",
    "    steps=10000, eta=.1, batchsize=200,\n",
    "                          visualize_nsteps=2000)\n",
    "\n",
    "timetaken = process_time()-start\n",
    "print(\"Time taken for output:\", timetaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Although a small cost value is obtained but the shape does not look very well as a circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased number of neurons\n",
    "\n",
    "`reLU` for first activation function for smooth curve around circle.\n",
    "<br>\n",
    "`jump` for final activation function for well defined circle.\n",
    "<br>\n",
    "One single later with 16 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = process_time()\n",
    "\n",
    "visualize_network_training(weights=[],biases=[],\n",
    "    num_neurons=[2,16,1], # this generates randomly initialized layers of the given neuron numbers!\n",
    "    bias_scale=0.0, weight_scale=0.1, # the scale of the random numbers\n",
    "    target_function=circle_target, # the target function to approximate\n",
    "    activations=[ \n",
    "                'reLU',\n",
    "                 'jump'\n",
    "                ],\n",
    "    x0range=[-3,3],x1range=[-3,3],\n",
    "    xspread=3,\n",
    "    steps=10000, eta=.1, batchsize=200,\n",
    "                          visualize_nsteps=2000)\n",
    "\n",
    "\n",
    "timetaken = process_time() - start\n",
    "print(\"Time taken for output:\", timetaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "A low costs value is obtained with just little process time difference compare to 8 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Combination\n",
    "\n",
    "Number of hidden layer: 1\n",
    "<br>\n",
    "Number of neurons: 16\n",
    "<br>\n",
    "Activation Functions: `reLU` ; `jump`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle hole target [40 points]\n",
    "Train a network to mimic the following target (e.g. using the visualize_network_training function above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_hole_target(x):#A circle of radius 2, with a hole of radius 1 around the origin\n",
    "    r=1.0; R=2.0\n",
    "    return( 1.0*( x[:,0]**2+x[:,1]**2<R**2 ) - 1.0*( (x[:,0])**2+(x[:,1])**2<r**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron network with only 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = process_time()\n",
    "\n",
    "visualize_network_training(weights=[],biases=[],\n",
    "    num_neurons=[2,32,1], # this generates randomly initialized layers of the given neuron numbers!\n",
    "    bias_scale=0.0, weight_scale=0.1, # the scale of the random numbers\n",
    "    target_function=circle_hole_target, # the target function to approximate\n",
    "    activations=[\n",
    "                'reLU',\n",
    "                 'jump'\n",
    "                ],\n",
    "    x0range=[-3,3],x1range=[-3,3],\n",
    "    xspread=3,\n",
    "    steps=10000, eta=.1, batchsize=200,\n",
    "                          visualize_nsteps=2500)\n",
    "\n",
    "timetaken = process_time()-start\n",
    "print(\"Time taken for output:\", timetaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "If we are only using to 1 hidden layer, 32 neuron numbers is needed for a decent plot and cost function which is bad for the simplicity of network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 hidden layers\n",
    "\n",
    "`reLU` are chosen for the first two activation function to ensure smooth curve around boundaries of circle and hole.\n",
    "<br>\n",
    "`jump` is used for well defined boundaries\n",
    "<br>\n",
    "Each hidden layer is given 8 neurons to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = process_time()\n",
    "\n",
    "visualize_network_training(weights=[],biases=[],\n",
    "    num_neurons=[2,8,8,1], # this generates randomly initialized layers of the given neuron numbers!\n",
    "    bias_scale=0.0, weight_scale=0.1, # the scale of the random numbers\n",
    "    target_function=circle_hole_target, # the target function to approximate\n",
    "    activations=[ 'reLU',\n",
    "                 'reLU',\n",
    "                 'jump'\n",
    "                ],\n",
    "    x0range=[-3,3],x1range=[-3,3],\n",
    "    xspread=3,\n",
    "    steps=10000, eta=.1, batchsize=200,\n",
    "                          visualize_nsteps=2500)\n",
    "\n",
    "timetaken = process_time()-start\n",
    "print(\"Time taken for output:\", timetaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "It is observed that the above code is not consistent as a good plot with low cost function is only obtain sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased number of neurons\n",
    "\n",
    "We are increasing the number of neurons in the hidden layer while trying to retain simplicity.\n",
    "<br>\n",
    "Also, the number of steps is increased by a factor of 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = process_time()\n",
    "\n",
    "visualize_network_training(weights=[],biases=[],\n",
    "    num_neurons=[2,12,6,1], # this generates randomly initialized layers of the given neuron numbers!\n",
    "    bias_scale=0.0, weight_scale=0.1, # the scale of the random numbers\n",
    "    target_function=circle_hole_target, # the target function to approximate\n",
    "    activations=[ 'reLU',\n",
    "                 'reLU',\n",
    "                 'jump'\n",
    "                ],\n",
    "    x0range=[-3,3],x1range=[-3,3],\n",
    "    xspread=3,\n",
    "    steps=15000, eta=.1, batchsize=200,\n",
    "                          visualize_nsteps=2500)\n",
    "\n",
    "timetaken = process_time()-start\n",
    "print(\"Time taken for output:\", timetaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Code works consistently produce a good plot with low cost value within an acceptable amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Combination\n",
    "\n",
    "Number of hidden layer: 2\n",
    "<br>\n",
    "Number of neurons: 12 ; 6\n",
    "<br>\n",
    "Activation Functions: `reLU` ; `reLU` ; `jump`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scream target [20 points]\n",
    "Train a network to mimic the following target (e.g. using the visualize_network_training function above). Note this target is much more difficult than the previous two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scream_target(x): #A circle of radius 2, two eyes of radius 0.5 and a mouth of radius 0.8\n",
    "    a=0.8; r=0.5; R=2.0; r2=0.8\n",
    "    return( 1.0*( x[:,0]**2+x[:,1]**2<R**2 ) - 1.0*( (x[:,0]-a)**2+(x[:,1]-a)**2<r**2) - 1.0*( (x[:,0]+a)**2+(x[:,1]-a)**2<r**2 ) - 1.0*( (x[:,0])**2+(x[:,1]+a)**2<r2**2 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 hidden layers\n",
    "\n",
    "Start with only 2 hidden layers with 16 and 8 neurons respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = process_time()\n",
    "\n",
    "visualize_network_training(weights=[],biases=[],\n",
    "    num_neurons=[2,16,8,1], # this generates randomly initialized layers of the given neuron numbers!\n",
    "    bias_scale=0.0, weight_scale=0.1, # the scale of the random numbers\n",
    "    target_function=scream_target, # the target function to approximate\n",
    "    activations=[ 'reLU',\n",
    "                 'reLU',\n",
    "                 'jump'\n",
    "                ],\n",
    "    x0range=[-3,3],x1range=[-3,3],\n",
    "    xspread=3,\n",
    "    steps=20000, eta=.1, batchsize=200,\n",
    "                          visualize_nsteps=2500)\n",
    "\n",
    "timetaken = process_time()-start\n",
    "print(\"Time taken for output:\", timetaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Final plot and cost function is not acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 hidden layers\n",
    "\n",
    "Using 3 hidden layers with 16, 8 , 4 number of neurons respectively.\n",
    "<br>\n",
    "Increased number of steps to 30000.\n",
    "<br>\n",
    "Increased batch size to 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = process_time()\n",
    "\n",
    "visualize_network_training(weights=[],biases=[],\n",
    "    num_neurons=[2,16,8,4,1], # this generates randomly initialized layers of the given neuron numbers!\n",
    "    bias_scale=0.0, weight_scale=0.1, # the scale of the random numbers\n",
    "    target_function=scream_target, # the target function to approximate\n",
    "    activations=[ 'reLU',\n",
    "                 'reLU',\n",
    "                 'reLU',\n",
    "                 'jump'\n",
    "                ],\n",
    "    x0range=[-3,3],x1range=[-3,3],\n",
    "    xspread=3,\n",
    "    steps=30000, eta=.1, batchsize=300,\n",
    "                          visualize_nsteps=5000)\n",
    "\n",
    "timetaken = process_time()-start\n",
    "print(\"Time taken for output:\", timetaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Code produces a decent plot and low costs value but not consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased number of neurons\n",
    "\n",
    "Increased number of neurons but only using 2 hidden layers. \n",
    "<br>\n",
    "Number of steps increase to 30000\n",
    "<br>\n",
    "Increased batch size to 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for output: 69.765625\n"
     ]
    }
   ],
   "source": [
    "start = process_time()\n",
    "\n",
    "visualize_network_training(weights=[],biases=[],\n",
    "    num_neurons=[2,32,16,1], # this generates randomly initialized layers of the given neuron numbers!\n",
    "    bias_scale=0.0, weight_scale=0.1, # the scale of the random numbers\n",
    "    target_function=scream_target, # the target function to approximate\n",
    "    activations=[ 'reLU',\n",
    "                 'reLU',\n",
    "                 'jump'\n",
    "                ],\n",
    "    x0range=[-3,3],x1range=[-3,3],\n",
    "    xspread=3,\n",
    "    steps=30000, eta=.1, batchsize=300,\n",
    "                          visualize_nsteps=5000)\n",
    "\n",
    "timetaken = process_time()-start\n",
    "print(\"Time taken for output:\", timetaken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Consistent code with good plot and low cost value with lesser time taken than 3 hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Combination\n",
    "\n",
    "Number of hidden layer: 2\n",
    "<br>\n",
    "Number of neurons: 32 ; 16\n",
    "<br>\n",
    "Activation Functions: `reLU` ; `reLU` ; `jump`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "A few different points have been concluded by trial and error relating different factors as shown below to **final costs function; simplicity; efficiency; clarity**\n",
    "\n",
    "**Number of Hidden Layers and Number of Neurons**: By increasing number of layers and number of neurons each layer, it is observed that a lower final costs function with good plot can be obtained but this would destroy the simplicity of code. Also, it takes longer for code to run with higher amount of hidden layers.\n",
    "\n",
    "**Activation Functions**: Activation function directly affects the output. If a wrong activation function is chosen, no matter how high the number of hidden layers or number of neurons is, a bad fit will alwayvs be obtain.\n",
    "\n",
    "**Number of steps**: By increasing the number of steps, it would be high likely for a good fit with low cost function. But, after a good fit is found the extra number of steps would be redundant as the costs function would just oscillate around the lowest value. Also increasing the number of steps would cause the code to run longer.\n",
    "\n",
    "**Batch Size**: Increasing the batch size would do little effect on getting a good fit with low cost value. Also, it is bad for efficiency as it takes a lot of computing power and time for a huge batch size.\n",
    "\n",
    "\n",
    "A good code for back propagation training is with a low number of hidden layers and number of neurons for code simplicity, a low number of steps and batch size for code efficiency and lower running time but still produces a good fit with low cost function. A balance is found by trial and error with some intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
